
## Read Customer Data

Load the cleaned customer data generated by Hive


```pyspark3
from pyspark.sql.types import *
from pyspark.sql.functions import *

custSchema = StructType([
        StructField("CustomerID", IntegerType(), False),
        StructField("CustomerName", StringType(), False),
        StructField("EmailAddress", StringType(), False),
        StructField("Phone", StringType(), False)
    ])
custData = spark.read.csv('wasb://bigdata@udaydatastorage.blob.core.windows.net/output', schema=custSchema, header=False,)
custData.show()
```

    Starting Spark application



<table>
<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1520055587426_0005</td><td>pyspark3</td><td>idle</td><td><a target="_blank" href="http://hn1-udaysp.kkolwflepb3epmlqy2rxxb1sba.rx.internal.cloudapp.net:8088/proxy/application_1520055587426_0005/">Link</a></td><td><a target="_blank" href="http://wn0-Udaysp.kkolwflepb3epmlqy2rxxb1sba.rx.internal.cloudapp.net:30060/node/containerlogs/container_1520055587426_0005_01_000001/livy">Link</a></td><td>âœ”</td></tr></table>


    SparkSession available as 'spark'.
    +----------+--------------------+--------------------+-------------------+
    |CustomerID|        CustomerName|        EmailAddress|              Phone|
    +----------+--------------------+--------------------+-------------------+
    |         1|  Mr. Orlando N. Gee|orlando0@adventur...|       245-555-0173|
    |         2|   Mr. Keith  Harris|keith0@adventure-...|       170-555-0127|
    |         3|Ms. Donna F. Carr...|donna0@adventure-...|       279-555-0130|
    |         4|  Ms. Janet M. Gates|janet1@adventure-...|       710-555-0173|
    |         5|Mr. Lucy  Harrington|lucy0@adventure-w...|       828-555-0186|
    |         6|Ms. Rosmarie J. C...|rosmarie0@adventu...|       244-555-0112|
    |         7| Mr. Dominic P. Gash|dominic0@adventur...|       192-555-0173|
    |        10|Ms. Kathleen M. G...|kathleen0@adventu...|       150-555-0127|
    |        11|Ms. Katherine  Ha...|katherine0@advent...|       926-555-0159|
    |        12|Mr. Johnny A. Caprio|johnny0@adventure...|       112-555-0191|
    |        16|Mr. Christopher R...|christopher1@adve...|1 (11) 500 555-0132|
    |        18|    Mr. David J. Liu|david20@adventure...|       440-555-0132|
    |        19|  Mr. John A. Beaver|john8@adventure-w...|       521-555-0195|
    |        20| Ms. Jean P. Handley|jean1@adventure-w...|       582-555-0113|
    |        21|        Jinghao  Liu|jinghao1@adventur...|       928-555-0116|
    |        22|Ms. Linda E. Burnett|linda4@adventure-...|       121-555-0121|
    |        23|    Mr. Kerim  Hanif|kerim0@adventure-...|       216-555-0122|
    |        24|      Mr. Kevin  Liu|kevin5@adventure-...|       926-555-0164|
    |        25|Mr. Donald L. Bla...|donald0@adventure...|       357-555-0161|
    |        28|Ms. Jackie E. Bla...|jackie0@adventure...|       972-555-0163|
    +----------+--------------------+--------------------+-------------------+
    only showing top 20 rows

Create a new dataframe containing only the name and phone number


```pyspark3
phoneBook = custData.select("CustomerName", "Phone")
phoneBook.show()
```

    +--------------------+-------------------+
    |        CustomerName|              Phone|
    +--------------------+-------------------+
    |  Mr. Orlando N. Gee|       245-555-0173|
    |   Mr. Keith  Harris|       170-555-0127|
    |Ms. Donna F. Carr...|       279-555-0130|
    |  Ms. Janet M. Gates|       710-555-0173|
    |Mr. Lucy  Harrington|       828-555-0186|
    |Ms. Rosmarie J. C...|       244-555-0112|
    | Mr. Dominic P. Gash|       192-555-0173|
    |Ms. Kathleen M. G...|       150-555-0127|
    |Ms. Katherine  Ha...|       926-555-0159|
    |Mr. Johnny A. Caprio|       112-555-0191|
    |Mr. Christopher R...|1 (11) 500 555-0132|
    |    Mr. David J. Liu|       440-555-0132|
    |  Mr. John A. Beaver|       521-555-0195|
    | Ms. Jean P. Handley|       582-555-0113|
    |        Jinghao  Liu|       928-555-0116|
    |Ms. Linda E. Burnett|       121-555-0121|
    |    Mr. Kerim  Hanif|       216-555-0122|
    |      Mr. Kevin  Liu|       926-555-0164|
    |Mr. Donald L. Bla...|       357-555-0161|
    |Ms. Jackie E. Bla...|       972-555-0163|
    +--------------------+-------------------+
    only showing top 20 rows

Now create a Spark SQL table


```pyspark3
phoneBook.createOrReplaceTempView("phoneBook")
```

Use inline SQL to query the table


```pyspark3
%%sql
SELECT CustomerName, Phone FROM phoneBook
WHERE CustomerName LIKE '%Kath%'
```


    

    AttributeErrorTraceback (most recent call last)

    /usr/bin/anaconda/lib/python2.7/site-packages/IPython/core/formatters.pyc in __call__(self, obj)
        902                 pass
        903             else:
    --> 904                 printer(obj)
        905                 return True
        906             # Finally look for special method names


    /usr/bin/anaconda/lib/python2.7/site-packages/autovizwidget/widget/utils.pyc in display_dataframe(df)
        114 
        115 def display_dataframe(df):
    --> 116     selected_x = select_x(df)
        117     selected_y = select_y(df, selected_x)
        118     encoding = Encoding(chart_type=Encoding.chart_type_table, x=selected_x, y=selected_y,


    /usr/bin/anaconda/lib/python2.7/site-packages/autovizwidget/widget/utils.pyc in select_x(data, order)
         70         _validate_custom_order(order)
         71 
    ---> 72     d = _classify_data_by_type(data, order)
         73 
         74     chosen_x = None


    /usr/bin/anaconda/lib/python2.7/site-packages/autovizwidget/widget/utils.pyc in _classify_data_by_type(data, order, skip)
         48     for column_name in data:
         49         if column_name not in skip:
    ---> 50             typ = infer_vegalite_type(data[column_name])
         51             d[typ].append(column_name)
         52 


    /usr/bin/anaconda/lib/python2.7/site-packages/autovizwidget/widget/utils.pyc in infer_vegalite_type(data)
         14     """
         15 
    ---> 16     typ = pd.api.types.infer_dtype(data)
         17 
         18     if typ in ['floating', 'mixed-integer-float', 'integer',


    AttributeError: 'module' object has no attribute 'api'





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CustomerName</th>
      <th>Phone</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Ms. Kathleen M. Garza</td>
      <td>150-555-0127</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Ms. Katherine  Harding</td>
      <td>926-555-0159</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Ms. Katherine K. Swan</td>
      <td>421-555-0192</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Ms. Kathie  Flood</td>
      <td>627-555-0192</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Ms. Kathy R. Marcovecchio</td>
      <td>942-555-0141</td>
    </tr>
  </tbody>
</table>
</div>




```pyspark3

```
